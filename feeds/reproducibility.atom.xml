<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ian Hawke</title><link href="http://IanHawke.github.io/blog/" rel="alternate"></link><link href="http://IanHawke.github.io/blog/feeds/reproducibility.atom.xml" rel="self"></link><id>http://IanHawke.github.io/blog/</id><updated>2015-06-01T09:00:00+01:00</updated><entry><title>The image is the simulation</title><link href="http://IanHawke.github.io/blog/the-image-is-the-simulation.html" rel="alternate"></link><updated>2015-06-01T09:00:00+01:00</updated><author><name>Ian Hawke</name></author><id>tag:IanHawke.github.io,2015-06-01:blog/the-image-is-the-simulation.html</id><summary type="html">&lt;p&gt;Reproducibility in science is of obvious importance, and the number of retractions and papers tackling this have highlighted the distance we still have to go. There's also been a lot of work on producing tools that make reproducibility easier, and a push to embed this through training. At the very least, the goals of the Recomputation Manifesto look to be closer now.&lt;/p&gt;
&lt;p&gt;My thought here is about &lt;em&gt;what&lt;/em&gt; is reproduced, not &lt;em&gt;how&lt;/em&gt;. In particular, what is it that represents a computer simulation?&lt;/p&gt;
&lt;h2&gt;Papers versus images&lt;/h2&gt;
&lt;p&gt;To most academics, the currency is papers and grants. As no funding agency has yet required a reproducible grant proposal, a lot of focus has gone into reproducible papers. At the same time, there's been a lot of comment that "the academic paper is dead or dying", or at least won't be fit for purpose in the near future. There's a minor conflict here, which may be one reason why reproducible &lt;em&gt;papers&lt;/em&gt; have gained less traction than reproducible &lt;em&gt;code&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Leaving that aside, to me the paper doesn't &lt;em&gt;represent&lt;/em&gt; the simulation. &lt;em&gt;My&lt;/em&gt; simulations build on detailed thought, carefully constructed code, and the best analysis I can produce of the complex resulting data. With the same level of seriousness, &lt;em&gt;your&lt;/em&gt; simulations are impressive work, but with weird voodoo magic I don't understand, and &lt;em&gt;their&lt;/em&gt; simulations are just a fancy visualization package on top of a random number generator.&lt;/p&gt;
&lt;p&gt;The serious point: to me, a simulation is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the problem being studied;&lt;/li&gt;
&lt;li&gt;the questions we're trying to answer;&lt;/li&gt;
&lt;li&gt;how widely applicable, and accurate, we think our answers are.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most of the detail that covers these points is summed up not in the paper, but in the figures and figure captions. The paper is "just" the framework and prose glue that holds the figures together.&lt;/p&gt;
&lt;p&gt;A computer science analogy comes from Brooks' quote adapted for Object Oriented programming by Raymond:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Show me your code without your [classes] and I won't understand. Show me your classes without your code, and I won't need to see the code.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I believe the analogy holds for simulation papers and images. A simulation paper without images will either be unintelligible or far too long to read. A good set of images can show the ideas and key content behind the paper without needing the paper.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Result of a pyro simulation" src="https://raw.githubusercontent.com/IanHawke/im2sim/master/example_figure/plot.png" /&gt;&lt;/p&gt;
&lt;p&gt;So, &lt;strong&gt;the image is the simulation&lt;/strong&gt;. And this is a &lt;em&gt;big&lt;/em&gt; problem.&lt;/p&gt;
&lt;h2&gt;The image as orphan&lt;/h2&gt;
&lt;p&gt;Hyperbole aside, images - unlike in-depth academic arguments - aren't confined to papers. Everywhere the work might be advertised - talks, websites, grant proposals and more - the image is doing much of the work: representing the simulation, standing in for the months of code wrangling and contentious analysis. That image that appeared on a student poster might, in a few years, be the key figure selling a grant proposal, or illustrating a research lab's work, or holding together a chapter of a thesis, or representing to another scientist all that is wrong (or right) about another field of research. How many problems result from people arguing about what they &lt;em&gt;think&lt;/em&gt; a result means, thanks to arguing with the figure out of context, and the original context (code and analysis) can't easily be reproduced?&lt;/p&gt;
&lt;p&gt;There is a link to be made with the amazing "artists' impressions" that NASA produces, often to illustrate new observational results. They're incredible feats that condense the state of the art science into easily grasped images. However, it's always clear that these aren't real. When the image is from a computer simulation, which is meant to be a cutting-edge model of how things "really" are, then it can have disproportionate impact on scientists and non-scientists when pulled out of context.&lt;/p&gt;
&lt;h2&gt;im2sim&lt;/h2&gt;
&lt;p&gt;One way to tackle this is to make the image &lt;em&gt;really&lt;/em&gt; represent the simulation, by making it possible to &lt;em&gt;replicate&lt;/em&gt; the full simulation (code, parameter files, data analysis scripts and all) just from the figure. Note that I'm using &lt;a href="http://reproduciblescience.blogspot.co.uk/2015/05/rebility.html"&gt;this definition&lt;/a&gt; of replicability versus reproducibility, even though I've loosely used reproducibility throughout this post. If the details are embedded in the figure metadata, in such a way that the simulation can be &lt;em&gt;easily&lt;/em&gt; recovered, then it would be possible to link the figure with its original context in a reproducible way.&lt;/p&gt;
&lt;p&gt;Here's an example, using the figure at the top of the page. To reproduce this figure, you'll need the &lt;code&gt;im2sim&lt;/code&gt; code from &lt;a href="http://ianhawke.github.com/im2sim"&gt;this github repository&lt;/a&gt;, which is a simple &lt;code&gt;python&lt;/code&gt; script, and the figure itself, which you can just "save as" directly from this page.&lt;/p&gt;
&lt;p&gt;The idea I've used here is the simplest hack I could think of that would give the entire simulation. The metadata of the image contains the SHA1 hash of a &lt;code&gt;docker&lt;/code&gt; container stored on &lt;a href="http://hub.docker.com"&gt;dockerhub&lt;/a&gt;. This container includes the code to produce it (in this case, &lt;code&gt;pyro2&lt;/code&gt;, which is Mike Zingale's code illustrating a number of CFD techniques) and a Makefile. &lt;code&gt;im2sim reproduce&lt;/code&gt; will (assuming you have &lt;code&gt;docker&lt;/code&gt; installed) pull the container, then tell you the command you need to run to reproduce the images, or the command to use to inspect the content of the container.&lt;/p&gt;
&lt;p&gt;The alternative use of the script can be illustrated once you have the container associated with the image. &lt;code&gt;im2sim mark&lt;/code&gt; can be called &lt;em&gt;on the container&lt;/em&gt;. This will run the Makefile in the container, produce the images, and then edit the metadata of the images to include the SHA1 hash. Those images can then be distributed, and anyone can reproduce the simulation using just the image and the &lt;code&gt;im2sim&lt;/code&gt; script.&lt;/p&gt;
&lt;h2&gt;Is this for everyone?&lt;/h2&gt;
&lt;p&gt;Let me rephrase that: should you download a script and image from the internet and run it on your machine, knowing that effective use of &lt;code&gt;docker&lt;/code&gt; requires root permission on your machine? The answer is obviously, "&lt;em&gt;No, you should not use this code!&lt;/em&gt;".&lt;/p&gt;
&lt;p&gt;However, building something like this into your workflow &lt;em&gt;would&lt;/em&gt; be a good idea. If you've already got a reproducible workflow then adding the metadata that gets back to the last analysis step producing the figures would be enough. Adding a link to, for example, a Jupyter notebook that produces the figure whilst explaining the analysis would be better. Any way that works!&lt;/p&gt;
&lt;h6&gt;Acknowledgements&lt;/h6&gt;
&lt;p&gt;The code to add the metadata to image files was &lt;a href="https://github.com/dfm/savefig"&gt;taken from this code&lt;/a&gt;. It monkey-patches &lt;code&gt;matplotlib&lt;/code&gt; to add the git hash of the local directory to the figure produced. This builds the reproducibility aspect into the workflow more naturally, and would be a better approach in many ways - it ensures the image automatically gets the metadata - but unlike the docker approach it doesn't contain the full workflow.&lt;/p&gt;
&lt;p&gt;The setup of the &lt;code&gt;docker&lt;/code&gt; container comes from &lt;a href="http://stackoverflow.com/a/26547845/3112941"&gt;this stackoverflow answer&lt;/a&gt; which references &lt;a href="https://github.com/marmelab/make-docker-command/blob/master/Makefile"&gt;this Makefile&lt;/a&gt;. I've taken the approach but switched to python simplly to use one script for the lot.&lt;/p&gt;
&lt;p&gt;Mike Zingale's &lt;code&gt;pyro2&lt;/code&gt; code covers a lot more than I've shown here. It's an excellent learning resource, especially used in conjunction with &lt;a href="https://github.com/Open-Astrophysics-Bookshelf/numerical_exercises"&gt;his detailed notes&lt;/a&gt;.&lt;/p&gt;</summary><category term="Reproducibility"></category></entry></feed>